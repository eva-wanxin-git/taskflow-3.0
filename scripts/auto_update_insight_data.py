#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨æ›´æ–°é€è§†å¡”æ•°æ®
ä»æ•°æ®åº“å®æ—¶ç»Ÿè®¡ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 
"""
import sqlite3
import json
from pathlib import Path
from datetime import datetime

# è·¯å¾„é…ç½®
PROJECT_ROOT = Path(__file__).parent.parent
DB_PATH = PROJECT_ROOT / "database" / "data" / "tasks.db"
DATA_DIR = PROJECT_ROOT / "apps" / "dashboard" / "automation-data"
OUTPUT_FILE = DATA_DIR / "v17-complete-features.json"

def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    return sqlite3.connect(str(DB_PATH))

def scan_completed_tasks():
    """æ‰«æå·²å®Œæˆçš„ä»»åŠ¡"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # æŸ¥è¯¢å·²å®Œæˆçš„ä»»åŠ¡ï¼ˆä¸åŒ…å«tagsåˆ—ï¼‰
    cursor.execute("""
        SELECT 
            id, title, description, status, priority,
            estimated_hours, created_at, completed_at,
            assigned_to, metadata
        FROM tasks
        WHERE status = 'completed'
        ORDER BY completed_at DESC
    """)
    
    completed_tasks = []
    for row in cursor.fetchall():
        completed_tasks.append({
            "id": row[0],
            "title": row[1],
            "description": row[2],
            "status": row[3],
            "priority": row[4],
            "estimated_hours": row[5],
            "created_at": row[6],
            "completed_at": row[7],
            "assigned_to": row[8],
            "metadata": row[9]
        })
    
    conn.close()
    return completed_tasks

def scan_project_files():
    """æ‰«æé¡¹ç›®æ–‡ä»¶ç»Ÿè®¡"""
    # ç»Ÿè®¡Pythonæ–‡ä»¶
    py_files = list(PROJECT_ROOT.rglob("*.py"))
    # ç»Ÿè®¡HTMLæ–‡ä»¶
    html_files = list(PROJECT_ROOT.rglob("*.html"))
    # ç»Ÿè®¡JSONæ–‡ä»¶
    json_files = list(PROJECT_ROOT.rglob("*.json"))
    
    total_lines = 0
    for py_file in py_files:
        try:
            with open(py_file, 'r', encoding='utf-8') as f:
                total_lines += len(f.readlines())
        except:
            pass
    
    return {
        "total_files": len(py_files) + len(html_files) + len(json_files),
        "py_files": len(py_files),
        "html_files": len(html_files),
        "json_files": len(json_files),
        "total_lines": total_lines
    }

def load_existing_features():
    """åŠ è½½ç°æœ‰åŠŸèƒ½æ¸…å•ä½œä¸ºåŸºç¡€"""
    if OUTPUT_FILE.exists():
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"implemented": []}

def update_features_data():
    """æ›´æ–°åŠŸèƒ½æ•°æ®"""
    print("\n" + "="*70)
    print("è‡ªåŠ¨æ›´æ–°é€è§†å¡”æ•°æ®")
    print("="*70)
    print()
    
    # 1. åŠ è½½ç°æœ‰åŠŸèƒ½æ¸…å•
    print("ğŸ“Š æ­¥éª¤1: åŠ è½½ç°æœ‰åŠŸèƒ½æ¸…å•...")
    existing_data = load_existing_features()
    existing_count = len(existing_data.get("implemented", []))
    print(f"   ç°æœ‰è®°å½•: {existing_count}ä¸ªåŠŸèƒ½")
    
    # 2. æ‰«æå·²å®Œæˆä»»åŠ¡
    print("\nğŸ“‹ æ­¥éª¤2: æ‰«ææ•°æ®åº“å·²å®Œæˆä»»åŠ¡...")
    completed_tasks = scan_completed_tasks()
    print(f"   å·²å®Œæˆä»»åŠ¡: {len(completed_tasks)}ä¸ª")
    
    # 3. æ‰«æé¡¹ç›®æ–‡ä»¶
    print("\nğŸ“ æ­¥éª¤3: æ‰«æé¡¹ç›®æ–‡ä»¶...")
    file_stats = scan_project_files()
    print(f"   æ€»æ–‡ä»¶æ•°: {file_stats['total_files']}")
    print(f"   Pythonæ–‡ä»¶: {file_stats['py_files']}")
    print(f"   HTMLæ–‡ä»¶: {file_stats['html_files']}")
    print(f"   ä»£ç è¡Œæ•°: {file_stats['total_lines']}")
    
    # 4. åˆå¹¶æ–°å®Œæˆçš„ä»»åŠ¡åˆ°åŠŸèƒ½æ¸…å•
    print("\nğŸ”„ æ­¥éª¤4: æ›´æ–°åŠŸèƒ½æ¸…å•...")
    implemented = existing_data.get("implemented", [])
    
    # å°†æ–°å®Œæˆçš„ä»»åŠ¡æ·»åŠ ä¸ºæ–°åŠŸèƒ½
    existing_ids = {f.get("id") for f in implemented}
    new_features = 0
    
    for task in completed_tasks:
        task_id = task["id"]
        if task_id not in existing_ids:
            # æ ¹æ®ä»»åŠ¡IDåˆ¤æ–­ç±»å‹
            task_type = "ä»»åŠ¡å®Œæˆ"
            if "REQ-" in task_id:
                task_type = "éœ€æ±‚å®ç°"
            elif "INTEGRATE-" in task_id:
                task_type = "é›†æˆåŠŸèƒ½"
            elif "TASK-" in task_id:
                task_type = "ä»»åŠ¡åŠŸèƒ½"
            
            implemented.append({
                "id": task_id,
                "name": task["title"],
                "type": task_type,
                "file": task.get("assigned_to", "unknown"),
                "version": "v1.9",
                "completion": 1.0,
                "completed_at": task.get("completed_at", ""),
                "priority": task.get("priority", "P2")
            })
            new_features += 1
    
    print(f"   æ–°å¢åŠŸèƒ½: {new_features}ä¸ª")
    print(f"   æ€»è®¡åŠŸèƒ½: {len(implemented)}ä¸ª")
    
    # 5. ä¿å­˜æ›´æ–°
    print("\nğŸ’¾ æ­¥éª¤5: ä¿å­˜æ•°æ®...")
    output_data = {
        "implemented": implemented,
        "summary": {
            "total": len(implemented),
            "last_scan": datetime.now().isoformat(),
            "scan_stats": file_stats
        }
    }
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"   âœ… å·²ä¿å­˜åˆ°: {OUTPUT_FILE}")
    
    # 6. æ€»ç»“
    print("\n" + "="*70)
    print("æ‰«æå®Œæˆ")
    print("="*70)
    print(f"\nåŠŸèƒ½æ•°é‡å˜åŒ–: {existing_count} â†’ {len(implemented)} (+{new_features})")
    print(f"å·²å®Œæˆä»»åŠ¡: {len(completed_tasks)}ä¸ª")
    print(f"é¡¹ç›®æ–‡ä»¶: {file_stats['total_files']}ä¸ª")
    print(f"ä»£ç è¡Œæ•°: {file_stats['total_lines']}è¡Œ")
    print()
    
    return {
        "old_count": existing_count,
        "new_count": len(implemented),
        "added": new_features,
        "completed_tasks": len(completed_tasks)
    }

if __name__ == "__main__":
    result = update_features_data()
    
    print("\nğŸ¯ å»ºè®®:")
    print("1. åˆ·æ–°Dashboard: http://localhost:8820")
    print("2. æˆ–ç‚¹å‡»é€è§†å¡”çš„'é‡æ–°æ‰«æ'æŒ‰é’®")
    print()

