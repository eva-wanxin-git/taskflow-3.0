#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå¯åŠ¨é€è§†å¡”APIæœåŠ¡
åªåŒ…å«é€è§†å¡”éœ€è¦çš„3ä¸ªæ–°ç«¯ç‚¹
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pathlib import Path
import json
from datetime import datetime
import uvicorn

app = FastAPI(title="é€è§†å¡”API", version="1.0.0")

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®æ–‡ä»¶è·¯å¾„
DATA_DIR = Path(__file__).parent / "apps" / "dashboard" / "automation-data"

def load_json_file(file_path: Path):
    """åŠ è½½JSONæ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

@app.get("/")
async def root():
    return {
        "name": "é€è§†å¡”API",
        "version": "1.0.0",
        "endpoints": {
            "features_implemented": "/api/features/implemented",
            "features_partial": "/api/features/partial",
            "issues": "/api/issues",
            "suggestions": "/api/suggestions",
            "architect_events": "/api/architect/events",
            "architect_monitor": "/api/architect/monitor",
            "architect_conversations": "/api/architect/conversations",
            "engineer_events": "/api/engineer/events",
            "engineer_conversations": "/api/engineer/conversations",
            "engineer_tasks": "/api/engineer/tasks",
            "engineer_task_accept": "/api/engineer/tasks/{task_id}/accept",
            "engineer_task_complete": "/api/engineer/tasks/{task_id}/complete",
            "engineer_reviews": "/api/engineer/reviews",
            "engineer_review_approve": "/api/engineer/reviews/{review_id}/approve",
            "engineer_review_reject": "/api/engineer/reviews/{review_id}/reject",
            "pulse_events": "/api/pulse/events",
            "memory_stats": "/api/projects/TASKFLOW/memories/stats",
            "memory_list": "/api/projects/TASKFLOW/memories"
        }
    }

@app.get("/api/features/implemented")
async def get_implemented_features():
    """è·å–å·²å®ç°åŠŸèƒ½åˆ—è¡¨"""
    data = load_json_file(DATA_DIR / "v17-complete-features.json")
    features = data.get("implemented", [])

    # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
    categories = {}
    for feature in features:
        category = feature.get("type", "å…¶ä»–")
        categories[category] = categories.get(category, 0) + 1

    return {
        "success": True,
        "total": len(features),
        "features": features,
        "categories": categories,
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/features/partial")
async def get_partial_features():
    """è·å–éƒ¨åˆ†å®ç°åŠŸèƒ½åˆ—è¡¨"""
    data = load_json_file(DATA_DIR / "partial-features.json")
    features = data.get("partial_features", [])

    # è®¡ç®—å¹³å‡è¿›åº¦
    avg_progress = sum(f.get("progress", 0) for f in features) / len(features) if features else 0

    return {
        "success": True,
        "total": len(features),
        "features": features,
        "avg_progress": round(avg_progress, 1),
        "updated_at": data.get("updated_at", datetime.now().isoformat())
    }

@app.get("/api/issues")
async def get_issues():
    """è·å–é—®é¢˜æ¸…å•"""
    data = load_json_file(DATA_DIR / "project-issues.json")
    issues = data.get("issues", [])

    # ç»Ÿè®¡
    priority_stats = {}
    severity_stats = {}
    total_hours = 0

    for issue in issues:
        p = issue.get("priority", "æœªçŸ¥")
        s = issue.get("severity", "æœªçŸ¥")
        priority_stats[p] = priority_stats.get(p, 0) + 1
        severity_stats[s] = severity_stats.get(s, 0) + 1
        total_hours += issue.get("estimated_hours", 0)

    return {
        "success": True,
        "total": len(issues),
        "issues": issues,
        "stats": {
            "by_priority": priority_stats,
            "by_severity": severity_stats,
            "total_estimated_hours": round(total_hours, 1)
        },
        "updated_at": data.get("updated_at", datetime.now().isoformat())
    }

@app.get("/api/suggestions")
async def get_suggestions():
    """è·å–æ¶æ„å»ºè®®æ¸…å•"""
    data = load_json_file(DATA_DIR / "architecture-suggestions.json")
    suggestions = data.get("suggestions", [])

    # ç»Ÿè®¡
    category_stats = {}
    priority_stats = {}
    total_hours = 0

    for sugg in suggestions:
        cat = sugg.get("category", "å…¶ä»–")
        pri = sugg.get("priority", "æœªçŸ¥")
        category_stats[cat] = category_stats.get(cat, 0) + 1
        priority_stats[pri] = priority_stats.get(pri, 0) + 1
        total_hours += sugg.get("estimated_hours", 0)

    # æŒ‰ä¼˜å…ˆçº§æ’åº
    priority_order = {"P0": 0, "P1": 1, "P2": 2, "P3": 3}
    suggestions.sort(key=lambda x: priority_order.get(x.get("priority", "P3"), 999))

    return {
        "success": True,
        "total": len(suggestions),
        "suggestions": suggestions,
        "stats": {
            "by_category": category_stats,
            "by_priority": priority_stats,
            "total_estimated_hours": round(total_hours, 1)
        },
        "updated_at": data.get("updated_at", datetime.now().isoformat())
    }

@app.get("/api/features/summary")
async def get_features_summary():
    """è·å–åŠŸèƒ½å®ç°æ¦‚å†µ"""
    complete_data = load_json_file(DATA_DIR / "v17-complete-features.json")
    partial_data = load_json_file(DATA_DIR / "partial-features.json")

    implemented_count = len(complete_data.get("implemented", []))
    partial_count = len(partial_data.get("partial_features", []))
    total = implemented_count + partial_count

    completion_rate = (implemented_count / total * 100) if total > 0 else 0

    return {
        "success": True,
        "implemented_count": implemented_count,
        "partial_count": partial_count,
        "total_features": total,
        "completion_rate": round(completion_rate, 1),
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/architect/events")
async def get_architect_events():
    """è·å–æ¶æ„å¸ˆäº‹ä»¶æµ"""
    data = load_json_file(DATA_DIR / "architect_events.json")
    events = data.get("events", [])

    return {
        "success": True,
        "total": len(events),
        "events": events,
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/architect/monitor")
async def get_architect_monitor():
    """è·å–æ¶æ„å¸ˆç›‘æ§æ•°æ®"""
    data = load_json_file(DATA_DIR / "architect_monitor.json")

    return {
        "success": True,
        "data": data,
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/architect/conversations")
async def get_architect_conversations():
    """è·å–æ¶æ„å¸ˆå¯¹è¯å†å²"""
    data = load_json_file(DATA_DIR / "architect-conversations.json")
    sessions = data.get("sessions", [])
    stats = data.get("stats", {})

    return {
        "success": True,
        "total": len(sessions),
        "sessions": sessions,
        "stats": stats,
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/dashboard/overview")
async def get_dashboard_overview():
    """è·å–Dashboardä¸»é¡µç»Ÿè®¡æ•°æ®"""
    # åŠ è½½å„ç§æ•°æ®
    architect_monitor = load_json_file(DATA_DIR / "architect_monitor.json")
    architect_events = load_json_file(DATA_DIR / "architect_events.json")
    architect_conversations = load_json_file(DATA_DIR / "architect-conversations.json")
    pulse_events = load_json_file(DATA_DIR / "realtime_pulse_events.json")

    # è®¡ç®—ä»»åŠ¡ç»Ÿè®¡ï¼ˆä»architect_monitorä¸­è·å–ï¼‰
    project_info = architect_monitor.get("project_info", {})
    total_tasks = project_info.get("total_tasks", 0)
    pending_tasks = project_info.get("pending_tasks", 0)
    completed_tasks = project_info.get("completed_tasks", 0)
    cancelled_tasks = project_info.get("cancelled_tasks", 0)
    in_progress_tasks = max(0, total_tasks - pending_tasks - completed_tasks - cancelled_tasks)  # ç¡®ä¿ä¸ä¸ºè´Ÿæ•°

    # Tokenä½¿ç”¨
    token_usage = architect_monitor.get("token_usage", {})
    token_used = token_usage.get("used", 0)

    # äº‹ä»¶æ•°ï¼ˆä»architect_eventsï¼‰
    total_architect_events = len(architect_events.get("events", []))

    # ä¼šè¯æ•°å’Œæ¶ˆæ¯æ•°
    conversations = architect_conversations.get("sessions", [])
    total_conversations = len(conversations)
    total_messages = sum(s.get("messages_count", 0) for s in conversations)

    # è®°å¿†æ•°ï¼ˆæš‚æ—¶ä½¿ç”¨å ä½æ•°æ®ï¼Œå®é™…åº”è¯¥ä»è®°å¿†ç³»ç»Ÿè·å–ï¼‰
    total_memories = 45
    memory_decisions = 12

    # ä»Šæ—¥å¢é‡
    today = datetime.now().strftime("%Y-%m-%d")
    today_events = [e for e in architect_events.get("events", []) if e.get("timestamp", "").startswith(today)]

    return {
        "success": True,
        "existing_stats": {
            "total_tasks": total_tasks,
            "pending_tasks": pending_tasks,
            "in_progress_tasks": in_progress_tasks,
            "completed_tasks": completed_tasks,
            "cancelled_tasks": cancelled_tasks,
            "token_used": token_used,
            "today_pending_change": len([e for e in today_events if e.get("type") == "task_create"]),
            "today_completed_change": len([e for e in today_events if e.get("type") == "task_complete"])
        },
        "new_stats": {
            "total_events": total_architect_events,
            "total_conversations": total_conversations,
            "total_messages": total_messages,
            "total_memories": total_memories,
            "memory_decisions": memory_decisions,
            "today_events_change": len(today_events)
        },
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/engineer/events")
async def get_engineer_events():
    """è·å–å…¨æ ˆå·¥ç¨‹å¸ˆäº‹ä»¶æµ"""
    data = load_json_file(DATA_DIR / "engineer_events.json")
    events = data.get("events", [])

    return {
        "success": True,
        "total": len(events),
        "events": events,
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/engineer/conversations")
async def get_engineer_conversations():
    """è·å–å…¨æ ˆå·¥ç¨‹å¸ˆå¯¹è¯å†å²"""
    data = load_json_file(DATA_DIR / "engineer-conversations.json")
    sessions = data.get("sessions", [])
    stats = data.get("stats", {})

    return {
        "success": True,
        "total": len(sessions),
        "sessions": sessions,
        "stats": stats,
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/engineer/tasks")
async def get_engineer_tasks():
    """è·å–å…¨æ ˆå·¥ç¨‹å¸ˆä»»åŠ¡åˆ—è¡¨ï¼ˆå®æ—¶ä»æ•°æ®åº“è¯»å–ï¼‰"""
    import sqlite3
    db_path = Path(__file__).parent / "database" / "data" / "tasks.db"

    try:
        conn = sqlite3.connect(str(db_path))
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # æŸ¥è¯¢æ‰€æœ‰å…¨æ ˆå·¥ç¨‹å¸ˆä»»åŠ¡ï¼ˆå®æ—¶æ•°æ®ï¼‰
        cursor.execute("""
            SELECT id, title, description, status, priority,
                   estimated_hours, actual_hours, complexity,
                   assigned_to, created_at, updated_at,
                   completed_at, metadata
            FROM tasks
            WHERE assigned_to IN ('fullstack-engineer', 'å…¨æ ˆå·¥ç¨‹å¸ˆ', 'ææ˜')
            ORDER BY
                CASE status
                    WHEN 'in_progress' THEN 1
                    WHEN 'pending' THEN 2
                    WHEN 'completed' THEN 3
                    ELSE 4
                END,
                CASE priority
                    WHEN 'P0' THEN 0
                    WHEN 'P1' THEN 1
                    WHEN 'P2' THEN 2
                    ELSE 3
                END,
                created_at DESC
        """)

        tasks = []
        for row in cursor.fetchall():
            task = dict(row)
            # ä»metadataè§£ætagså’Œparallel
            if task.get('metadata'):
                try:
                    metadata = json.loads(task['metadata'])
                    task['tags'] = metadata.get('tags', [])
                    task['parallel'] = metadata.get('parallel', False)
                except:
                    task['tags'] = []
                    task['parallel'] = False
            else:
                task['tags'] = []
                task['parallel'] = False
            tasks.append(task)

        # æŒ‰çŠ¶æ€åˆ†ç»„
        tasks_by_status = {
            'pending': [t for t in tasks if t['status'] == 'pending'],
            'in_progress': [t for t in tasks if t['status'] == 'in_progress'],
            'completed': [t for t in tasks if t['status'] == 'completed']
        }

        stats = {
            'total': len(tasks),
            'pending': len(tasks_by_status['pending']),
            'in_progress': len(tasks_by_status['in_progress']),
            'completed': len(tasks_by_status['completed'])
        }

        conn.close()

        return {
            "success": True,
            "total": len(tasks),
            "tasks": tasks,
            "tasks_by_status": tasks_by_status,
            "stats": stats,
            "updated_at": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"è·å–ä»»åŠ¡å¤±è´¥: {str(e)}",
            "error": str(e),
            "tasks": [],
            "stats": {"total": 0, "pending": 0, "in_progress": 0, "completed": 0}
        }

# æ—§çš„æ•°æ®åº“æŸ¥è¯¢ç‰ˆæœ¬ï¼ˆå·²åºŸå¼ƒï¼‰
@app.get("/api/engineer/tasks/old")
async def get_engineer_tasks_old():
    """è·å–å…¨æ ˆå·¥ç¨‹å¸ˆä»»åŠ¡åˆ—è¡¨ï¼ˆä»æ•°æ®åº“è¯»å–å®æ—¶æ•°æ®ï¼‰- å·²åºŸå¼ƒ"""
    import sqlite3
    db_path = Path(__file__).parent / "database" / "data" / "tasks.db"

    try:
        conn = sqlite3.connect(str(db_path))
        conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸æ ¼å¼
        cursor = conn.cursor()

        # æŸ¥è¯¢æ‰€æœ‰å…¨æ ˆå·¥ç¨‹å¸ˆä»»åŠ¡ï¼ˆä¸æŸ¥è¯¢tagså’Œparallelåˆ—ï¼‰
        cursor.execute("""
            SELECT id, title, description, status, priority,
                   estimated_hours, actual_hours, complexity,
                   assigned_to, metadata,
                   created_at, updated_at, completed_at
            FROM tasks
            WHERE assigned_to = 'fullstack-engineer'
            ORDER BY
                CASE priority
                    WHEN 'P0' THEN 0
                    WHEN 'P1' THEN 1
                    WHEN 'P2' THEN 2
                    WHEN 'P3' THEN 3
                    ELSE 4
                END,
                created_at DESC
        """)

        rows = cursor.fetchall()
        tasks = [dict(row) for row in rows]

        # ç»Ÿè®¡å„çŠ¶æ€ä»»åŠ¡æ•°
        stats = {
            "pending": 0,
            "in_progress": 0,
            "completed": 0
        }

        for task in tasks:
            status = task.get("status", "pending")
            if status in stats:
                stats[status] += 1

        conn.close()

        return {
            "success": True,
            "total": len(tasks),
            "tasks": tasks,
            "stats": stats,
            "updated_at": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}",
            "error": str(e),
            "tasks": [],
            "stats": {"pending": 0, "in_progress": 0, "completed": 0}
        }

@app.post("/api/engineer/tasks/{task_id}/accept")
async def accept_task(task_id: str):
    """æ¥å—ä»»åŠ¡ - çŠ¶æ€ä»pendingå˜ä¸ºin_progress"""
    import sqlite3
    db_path = Path(__file__).parent / "database" / "data" / "tasks.db"

    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        cursor.execute("""
            UPDATE tasks
            SET status = 'in_progress',
                updated_at = datetime('now'),
                assigned_at = datetime('now')
            WHERE id = ?
        """, (task_id,))

        conn.commit()
        conn.close()

        return {
            "success": True,
            "message": f"ä»»åŠ¡ {task_id} å·²æ¥å—ï¼ŒçŠ¶æ€æ›´æ–°ä¸ºè¿›è¡Œä¸­",
            "task_id": task_id,
            "new_status": "in_progress",
            "updated_at": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"æ¥å—ä»»åŠ¡å¤±è´¥: {str(e)}",
            "error": str(e)
        }

@app.post("/api/engineer/tasks/{task_id}/complete")
async def complete_task(task_id: str, completion_data: dict):
    """æäº¤å®ŒæˆæŠ¥å‘Š - çŠ¶æ€ä»in_progresså˜ä¸ºcompleted"""
    import sqlite3
    db_path = Path(__file__).parent / "database" / "data" / "tasks.db"

    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()

        # è·å–ä»»åŠ¡çš„å®é™…å·¥æ—¶
        actual_hours = completion_data.get("actual_hours", 0)

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        cursor.execute("""
            UPDATE tasks
            SET status = 'completed',
                actual_hours = ?,
                updated_at = datetime('now'),
                completed_at = datetime('now')
            WHERE id = ?
        """, (actual_hours, task_id))

        # æ’å…¥æˆ–æ›´æ–°å®Œæˆè¯¦æƒ…
        cursor.execute("""
            INSERT OR REPLACE INTO task_completions
            (task_id, features_implemented, files_created, files_modified,
             code_lines, actual_hours, notes, completed_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, datetime('now'))
        """, (
            task_id,
            json.dumps(completion_data.get("features", []), ensure_ascii=False),
            json.dumps(completion_data.get("files_created", []), ensure_ascii=False),
            json.dumps(completion_data.get("files_modified", []), ensure_ascii=False),
            completion_data.get("code_lines", 0),
            actual_hours,
            completion_data.get("notes", "")
        ))

        conn.commit()
        conn.close()

        return {
            "success": True,
            "message": f"ä»»åŠ¡ {task_id} å·²å®Œæˆ",
            "task_id": task_id,
            "new_status": "completed",
            "actual_hours": actual_hours,
            "updated_at": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"æäº¤å®Œæˆå¤±è´¥: {str(e)}",
            "error": str(e)
        }

# ============================================
# ä»£ç å®¡æŸ¥ç›¸å…³API
# ============================================

@app.get("/api/engineer/reviews")
async def get_code_reviews():
    """è·å–ä»£ç å®¡æŸ¥åˆ—è¡¨"""
    data = load_json_file(DATA_DIR / "engineer-code-reviews.json")
    reviews = data.get("reviews", [])
    stats = data.get("stats", {})

    return {
        "success": True,
        "total": len(reviews),
        "reviews": reviews,
        "stats": stats,
        "updated_at": datetime.now().isoformat()
    }

@app.post("/api/engineer/reviews/{review_id}/approve")
async def approve_review(review_id: str):
    """é€šè¿‡ä»£ç å®¡æŸ¥"""
    data_file = DATA_DIR / "engineer-code-reviews.json"
    data = load_json_file(data_file)

    # æŸ¥æ‰¾å®¡æŸ¥è®°å½•
    review = None
    for r in data.get("reviews", []):
        if r["review_id"] == review_id:
            review = r
            break

    if not review:
        return {
            "success": False,
            "message": f"å®¡æŸ¥è®°å½• {review_id} ä¸å­˜åœ¨"
        }

    # æ›´æ–°çŠ¶æ€
    review["status"] = "approved"
    review["reviewed_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # æ›´æ–°ç»Ÿè®¡
    data["stats"]["pending_review"] = data["stats"].get("pending_review", 0) - 1
    data["stats"]["approved"] = data["stats"].get("approved", 0) + 1

    # ä¿å­˜æ–‡ä»¶
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return {
        "success": True,
        "message": f"å®¡æŸ¥ {review_id} å·²é€šè¿‡",
        "review_id": review_id,
        "task_id": review["task_id"],
        "new_status": "approved",
        "updated_at": datetime.now().isoformat()
    }

@app.post("/api/engineer/reviews/{review_id}/reject")
async def reject_review(review_id: str, reject_data: dict):
    """æ‹’ç»ä»£ç å®¡æŸ¥ï¼Œè¦æ±‚ä¿®æ”¹"""
    data_file = DATA_DIR / "engineer-code-reviews.json"
    data = load_json_file(data_file)

    # æŸ¥æ‰¾å®¡æŸ¥è®°å½•
    review = None
    for r in data.get("reviews", []):
        if r["review_id"] == review_id:
            review = r
            break

    if not review:
        return {
            "success": False,
            "message": f"å®¡æŸ¥è®°å½• {review_id} ä¸å­˜åœ¨"
        }

    # æ›´æ–°çŠ¶æ€
    review["status"] = "rejected"
    review["reviewed_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    review["review_notes"] = reject_data.get("notes", "éœ€è¦ä¿®æ”¹")

    # æ›´æ–°ç»Ÿè®¡
    data["stats"]["pending_review"] = data["stats"].get("pending_review", 0) - 1
    data["stats"]["rejected"] = data["stats"].get("rejected", 0) + 1

    # ä¿å­˜æ–‡ä»¶
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return {
        "success": True,
        "message": f"å®¡æŸ¥ {review_id} å·²æ‹’ç»ï¼Œè¦æ±‚ä¿®æ”¹",
        "review_id": review_id,
        "task_id": review["task_id"],
        "new_status": "rejected",
        "notes": reject_data.get("notes", ""),
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/pending-tasks")
async def get_pending_tasks():
    """è·å–å¾…å¼€å‘ä»»åŠ¡æ± æ•°æ®"""
    data = load_json_file(DATA_DIR / "pending_tasks.json")
    user_requirements = data.get("user_requirements", [])
    architect_suggestions = data.get("architect_suggestions", [])
    stats = data.get("stats", {})

    return {
        "success": True,
        "user_requirements": user_requirements,
        "architect_suggestions": architect_suggestions,
        "stats": stats,
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/projects/TASKFLOW/memories/stats")
async def get_memory_stats():
    """è·å–é¡¹ç›®è®°å¿†ç»Ÿè®¡"""
    import sqlite3
    db_path = Path(__file__).parent / "database" / "data" / "tasks.db"

    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()

        # æŸ¥è¯¢ç»Ÿè®¡
        cursor.execute("""
            SELECT
                COUNT(*) as total,
                SUM(CASE WHEN memory_type = 'decision' THEN 1 ELSE 0 END) as decisions,
                SUM(CASE WHEN memory_type = 'solution' THEN 1 ELSE 0 END) as solutions,
                SUM(CASE WHEN category = 'knowledge' THEN 1 ELSE 0 END) as knowledge,
                SUM(CASE WHEN importance >= 8 THEN 1 ELSE 0 END) as important
            FROM project_memories
            WHERE project_id = 'TASKFLOW'
        """)
        row = cursor.fetchone()
        conn.close()

        return {
            "success": True,
            "project_id": "TASKFLOW",
            "stats": {
                "total_memories": row[0] if row else 0,
                "decision_memories": row[1] if row else 0,
                "solution_memories": row[2] if row else 0,
                "by_category": {"knowledge": row[3] if row else 0},
                "by_importance": {"critical (9-10)": row[4] if row else 0},
                "last_updated": datetime.now().isoformat()
            }
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/projects/TASKFLOW/memories")
async def get_memories():
    """è·å–é¡¹ç›®è®°å¿†åˆ—è¡¨"""
    import sqlite3
    db_path = Path(__file__).parent / "database" / "data" / "tasks.db"

    try:
        conn = sqlite3.connect(str(db_path))
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        cursor.execute("""
            SELECT * FROM project_memories
            WHERE project_id = 'TASKFLOW'
            ORDER BY importance DESC, created_at DESC
            LIMIT 50
        """)
        rows = cursor.fetchall()

        memories = []
        for row in rows:
            memory = dict(row)
            # è§£æJSONå­—æ®µ
            for field in ['tags', 'related_tasks', 'related_issues']:
                if memory.get(field):
                    try:
                        memory[field] = json.loads(memory[field])
                    except:
                        memory[field] = []
            memories.append(memory)

        conn.close()

        return {
            "success": True,
            "project_id": "TASKFLOW",
            "memories": memories,
            "count": len(memories),
            "retrieved_at": datetime.now().isoformat()
        }
    except Exception as e:
        return {"success": False, "error": str(e), "memories": []}

@app.get("/api/pulse/events")
async def get_pulse_events():
    """è·å–å®æ—¶è„‰åŠ¨äº‹ä»¶æµï¼ˆå…¨è§’è‰²ï¼‰"""
    data = load_json_file(DATA_DIR / "realtime_pulse_events.json")
    events = data.get("events", [])
    stats = data.get("stats", {})

    # æŒ‰æ—¶é—´å€’åºæ’åˆ—
    events_sorted = sorted(events, key=lambda x: x.get("timestamp", ""), reverse=True)

    return {
        "success": True,
        "total": len(events_sorted),
        "events": events_sorted,
        "stats": stats,
        "updated_at": datetime.now().isoformat()
    }

@app.post("/api/architect/save-conversation")
async def save_conversation(conversation: dict):
    """ä¿å­˜æ–°çš„å¯¹è¯è®°å½•"""
    try:
        file_path = DATA_DIR / "architect-conversations.json"

        # è¯»å–ç°æœ‰æ•°æ®
        data = load_json_file(file_path)
        sessions = data.get("sessions", [])

        # ç”Ÿæˆæ–°çš„session_id
        session_id = f"conv-{str(len(sessions) + 1).zfill(3)}"

        # æ„å»ºæ–°å¯¹è¯è®°å½•
        new_session = {
            "session_id": session_id,
            "title": conversation.get("title", "æœªå‘½åå¯¹è¯"),
            "project_id": conversation.get("project_id", "TASKFLOW"),
            "model": conversation.get("model", "claude-3-5-sonnet-4"),
            "status": conversation.get("status", "completed"),
            "total_tokens": conversation.get("total_tokens", 0),
            "messages_count": conversation.get("messages_count", 0),
            "created_at": conversation.get("created_at", datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
            "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "participants": conversation.get("participants", ["ç”¨æˆ·", "AIæ¶æ„å¸ˆ"]),
            "summary": conversation.get("summary", ""),
            "messages": [],
            "started_at": conversation.get("started_at", datetime.now().isoformat()),
            "last_active": datetime.now().isoformat(),
            "tags": conversation.get("tags", [])
        }

        # æ·»åŠ åˆ°åˆ—è¡¨
        sessions.append(new_session)

        # æ›´æ–°ç»Ÿè®¡
        data["sessions"] = sessions
        data["stats"] = {
            "total_conversations": len(sessions),
            "active_conversations": sum(1 for s in sessions if s.get("status") == "active"),
            "total_tokens": sum(s.get("total_tokens", 0) for s in sessions),
            "total_messages": sum(s.get("messages_count", 0) for s in sessions),
            "last_updated": datetime.now().isoformat()
        }

        # å†™å…¥æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        return {
            "success": True,
            "message": "å¯¹è¯è®°å½•å·²ä¿å­˜",
            "session_id": session_id,
            "updated_at": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"ä¿å­˜å¤±è´¥: {str(e)}"
        }

@app.post("/api/rescan")
async def trigger_rescan():
    """è§¦å‘é‡æ–°æ‰«æé¡¹ç›® - è¿”å›å®æ—¶ç»Ÿè®¡"""
    import subprocess
    from pathlib import Path

    project_root = Path(__file__).parent
    script_path = project_root / "scripts" / "auto_update_insight_data.py"

    if not script_path.exists():
        return {
            "success": False,
            "message": "æ‰«æè„šæœ¬ä¸å­˜åœ¨",
            "path": str(script_path)
        }

    try:
        # è¿è¡Œæ‰«æè„šæœ¬
        result = subprocess.run(
            ["python3", str(script_path)],
            capture_output=True,
            text=True,
            timeout=30
        )

        if result.returncode == 0:
            # é‡æ–°åŠ è½½æ›´æ–°åçš„æ•°æ®
            complete_data = load_json_file(DATA_DIR / "v17-complete-features.json")

            # æå–ç»Ÿè®¡ä¿¡æ¯
            scan_stats = complete_data.get("summary", {}).get("scan_stats", {})

            return {
                "success": True,
                "message": "æ‰«æå®Œæˆï¼Œæ•°æ®å·²æ›´æ–°",
                "stats": {
                    "features_count": len(complete_data.get("implemented", [])),
                    "files_count": scan_stats.get("total_files", 0),
                    "lines_count": scan_stats.get("total_lines", 0),
                    "py_files": scan_stats.get("py_files", 0),
                    "html_files": scan_stats.get("html_files", 0),
                    "json_files": scan_stats.get("json_files", 0)
                },
                "scan_time": datetime.now().isoformat()
            }
        else:
            return {
                "success": False,
                "message": "æ‰«æå¤±è´¥",
                "error": result.stderr
            }
    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "message": "æ‰«æè¶…æ—¶ï¼ˆ>30ç§’ï¼‰"
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"æ‰«æå¼‚å¸¸: {str(e)}"
        }

# ============================================================================
# è®°å¿†ç©ºé—´APIç«¯ç‚¹
# ============================================================================

# å†…å­˜å­˜å‚¨è®°å¿†æ•°æ®ï¼ˆç®€å•å®ç°ï¼‰
memories_storage = []

@app.get("/api/memories/stats")
async def get_memory_stats():
    """è·å–è®°å¿†ç»Ÿè®¡æ•°æ®"""
    # ä»å†…å­˜ä¸­ç»Ÿè®¡
    total = len(memories_storage)
    decision_count = sum(1 for m in memories_storage if m.get('type') == 'decision')
    solution_count = sum(1 for m in memories_storage if m.get('type') == 'solution')
    important_count = sum(1 for m in memories_storage if m.get('importance', 5) >= 9)

    return {
        "success": True,
        "stats": {
            "total_memories": total,
            "decision_memories": decision_count,
            "solution_memories": solution_count,
            "by_importance": {
                "critical (9-10)": important_count
            }
        },
        "updated_at": datetime.now().isoformat()
    }

@app.get("/api/memories")
async def get_memories():
    """è·å–è®°å¿†åˆ—è¡¨"""
    return {
        "success": True,
        "memories": memories_storage,
        "count": len(memories_storage),
        "updated_at": datetime.now().isoformat()
    }

@app.post("/api/memories")
async def create_memory(memory_data: dict):
    """åˆ›å»ºæ–°è®°å¿†"""
    new_memory = {
        "id": f"mem_{len(memories_storage) + 1}_{datetime.now().strftime('%H%M%S')}",
        "title": memory_data.get("title"),
        "content": memory_data.get("content"),
        "memory_type": memory_data.get("type", "knowledge"),
        "category": memory_data.get("type", "knowledge"),
        "type": memory_data.get("type", "knowledge"),
        "importance": 5,
        "created_by": "ç”¨æˆ·",
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "tags": memory_data.get("tags", [])
    }

    memories_storage.append(new_memory)

    return {
        "success": True,
        "message": "è®°å¿†åˆ›å»ºæˆåŠŸ",
        "memory": new_memory
    }

@app.post("/api/update_project_info")
async def update_project_info(request: Request):
    """æ›´æ–°é¡¹ç›®ä¿¡æ¯ï¼ˆæ¶æ„å¸ˆæ¿€æ´»åè°ƒç”¨ï¼‰"""
    try:
        data = await request.json()

        # ä¿å­˜é¡¹ç›®ä¿¡æ¯åˆ°é…ç½®æ–‡ä»¶
        config_file = Path(__file__).parent / ".taskflow" / "project_info.json"
        config_file.parent.mkdir(exist_ok=True)

        project_info = {
            "project_name": data.get("project_name"),
            "description": data.get("description"),
            "tech_stack": data.get("tech_stack", []),
            "components": data.get("components", []),
            "estimated_time": data.get("estimated_time"),
            "updated_at": datetime.now().isoformat(),
            "updated_by": "architect_ai"
        }

        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(project_info, f, indent=2, ensure_ascii=False)

        return {
            "success": True,
            "message": "é¡¹ç›®ä¿¡æ¯å·²æ›´æ–°",
            "data": project_info
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/get_project_info")
async def get_project_info():
    """è·å–é¡¹ç›®ä¿¡æ¯"""
    config_file = Path(__file__).parent / ".taskflow" / "project_info.json"

    if config_file.exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    # è¿”å›é»˜è®¤ä¿¡æ¯
    project_name = Path(__file__).parent.name
    return {
        "project_name": project_name,
        "description": "ä¼ä¸šçº§AIä»»åŠ¡ä¸­æ¿ | å¤šé¡¹ç›®æ”¯æŒ Â· æ™ºèƒ½è·Ÿè¸ªç®¡ç†",
        "tech_stack": "æ£€æµ‹ä¸­...",
        "estimated_time": "å¾…åˆ†æ"
    }

@app.post("/api/initialize_memory_space")
async def initialize_memory_space(request: Request):
    """åˆå§‹åŒ–ç‹¬ç«‹é¡¹ç›®è®°å¿†ç©ºé—´"""
    try:
        data = await request.json()
        project_code = data.get("project_code")
        project_id = data.get("project_id")

        # åˆ›å»ºæœ¬åœ°è®°å¿†ç©ºé—´
        memory_dir = Path(__file__).parent / ".taskflow" / "memories" / project_id
        memory_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºå­ç›®å½•
        (memory_dir / "conversations").mkdir(exist_ok=True)
        (memory_dir / "decisions").mkdir(exist_ok=True)
        (memory_dir / "solutions").mkdir(exist_ok=True)
        (memory_dir / "knowledge").mkdir(exist_ok=True)

        # åˆ›å»ºå…ƒæ•°æ®
        metadata = {
            "project_code": project_code,
            "project_id": project_id,
            "created_at": datetime.now().isoformat(),
            "mcp_namespaces": {
                "session": f"{project_code}_sessions",
                "ultra": f"{project_code}_ultra"
            }
        }

        with open(memory_dir / "metadata.json", 'w') as f:
            json.dump(metadata, f, indent=2)

        return {
            "success": True,
            "message": "è®°å¿†ç©ºé—´å·²åˆ›å»º",
            "memory_dir": str(memory_dir),
            "namespaces": metadata["mcp_namespaces"]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/activation_commands/{role}")
async def get_activation_command(role: str):
    """è·å–æŒ‡å®šè§’è‰²çš„æ¿€æ´»æŒ‡ä»¤"""
    try:
        commands_file = Path(__file__).parent / ".taskflow" / "activation_commands.json"

        if commands_file.exists():
            with open(commands_file, 'r', encoding='utf-8') as f:
                commands = json.load(f)

            if role in commands:
                return {
                    "success": True,
                    "role": role,
                    "command": commands[role]
                }
            else:
                raise HTTPException(status_code=404, detail=f"è§’è‰² {role} ä¸å­˜åœ¨")
        else:
            raise HTTPException(status_code=404, detail="æ¿€æ´»æŒ‡ä»¤æœªç”Ÿæˆï¼Œè¯·å…ˆåˆå§‹åŒ–é¡¹ç›®")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/activation_commands")
async def get_all_activation_commands():
    """è·å–æ‰€æœ‰è§’è‰²çš„æ¿€æ´»æŒ‡ä»¤"""
    try:
        commands_file = Path(__file__).parent / ".taskflow" / "activation_commands.json"

        if commands_file.exists():
            with open(commands_file, 'r', encoding='utf-8') as f:
                commands = json.load(f)

            return {
                "success": True,
                "commands": commands,
                "roles": list(commands.keys())
            }
        else:
            return {
                "success": False,
                "message": "æ¿€æ´»æŒ‡ä»¤æœªç”Ÿæˆï¼Œè¯·å…ˆåˆå§‹åŒ–é¡¹ç›®",
                "commands": {},
                "roles": []
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    print("\n" + "="*60)
    print("é€è§†å¡”APIæœåŠ¡".center(60))
    print("="*60)
    print(f"\nç«¯å£: 8800")
    print(f"æ•°æ®ç›®å½•: {DATA_DIR}")

    # å¯åŠ¨å‰è‡ªåŠ¨æ‰«ææ›´æ–°æ•°æ®
    print(f"\nğŸ”„ è‡ªåŠ¨æ‰«æé¡¹ç›®æ•°æ®...")
    import subprocess

    script_path = Path(__file__).parent / "scripts" / "auto_update_insight_data.py"
    if script_path.exists():
        try:
            result = subprocess.run(
                ["python3", str(script_path)],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                # ä»è¾“å‡ºä¸­æå–å…³é”®ä¿¡æ¯
                if "åŠŸèƒ½æ•°é‡å˜åŒ–:" in result.stdout:
                    for line in result.stdout.split('\n'):
                        if "åŠŸèƒ½æ•°é‡å˜åŒ–:" in line or "å·²å®Œæˆä»»åŠ¡:" in line or "ä»£ç è¡Œæ•°:" in line:
                            print(f"   {line.strip()}")
                print(f"   âœ… æ•°æ®å·²æ›´æ–°")
            else:
                print(f"   âš ï¸ æ‰«æå¤±è´¥: {result.stderr[:200]}")
        except Exception as e:
            print(f"   âš ï¸ æ‰«æå¼‚å¸¸: {str(e)}")
    else:
        print(f"   âš ï¸ æ‰«æè„šæœ¬ä¸å­˜åœ¨: {script_path}")

    print(f"\nğŸš€ å¯åŠ¨APIæœåŠ¡...")
    print("="*60 + "\n")

    uvicorn.run(app, host="127.0.0.1", port=8800, log_level="info")

